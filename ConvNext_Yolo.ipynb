{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20598cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in ./myenv/lib/python3.12/site-packages (8.3.191)\n",
      "Requirement already satisfied: numpy>=1.23.0 in ./myenv/lib/python3.12/site-packages (from ultralytics) (2.2.6)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in ./myenv/lib/python3.12/site-packages (from ultralytics) (3.10.5)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in ./myenv/lib/python3.12/site-packages (from ultralytics) (4.12.0.88)\n",
      "Requirement already satisfied: pillow>=7.1.2 in ./myenv/lib/python3.12/site-packages (from ultralytics) (11.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in ./myenv/lib/python3.12/site-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in ./myenv/lib/python3.12/site-packages (from ultralytics) (2.32.5)\n",
      "Requirement already satisfied: scipy>=1.4.1 in ./myenv/lib/python3.12/site-packages (from ultralytics) (1.16.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in ./myenv/lib/python3.12/site-packages (from ultralytics) (2.8.0)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in ./myenv/lib/python3.12/site-packages (from ultralytics) (0.23.0)\n",
      "Requirement already satisfied: psutil in ./myenv/lib/python3.12/site-packages (from ultralytics) (7.0.0)\n",
      "Requirement already satisfied: py-cpuinfo in ./myenv/lib/python3.12/site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: polars in ./myenv/lib/python3.12/site-packages (from ultralytics) (1.33.0)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in ./myenv/lib/python3.12/site-packages (from ultralytics) (2.0.16)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./myenv/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in ./myenv/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./myenv/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (4.59.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./myenv/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in ./myenv/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./myenv/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./myenv/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./myenv/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./myenv/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./myenv/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./myenv/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (2025.8.3)\n",
      "Requirement already satisfied: filelock in ./myenv/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./myenv/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
      "Requirement already satisfied: setuptools in ./myenv/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./myenv/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
      "Requirement already satisfied: networkx in ./myenv/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
      "Requirement already satisfied: jinja2 in ./myenv/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
      "Requirement already satisfied: fsspec in ./myenv/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (2025.7.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in ./myenv/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in ./myenv/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in ./myenv/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in ./myenv/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in ./myenv/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in ./myenv/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in ./myenv/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in ./myenv/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in ./myenv/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in ./myenv/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in ./myenv/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in ./myenv/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in ./myenv/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in ./myenv/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.4.0 in ./myenv/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.4.0)\n",
      "Requirement already satisfied: six>=1.5 in ./myenv/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./myenv/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./myenv/lib/python3.12/site-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ultralytics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bda95262",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import DINOv3ConvNextModel, DINOv3ConvNextConfig\n",
    "from huggingface_hub import login\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6a99b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from ultralytics.nn.modules import Detect\n",
    "from ultralytics.nn.tasks import DetectionModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21ffeece",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "login(new_session=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62a1f585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...existing code...\n",
    "class ConvNextBackboneAdapter(nn.Module):\n",
    "    \"\"\"\n",
    "    Adapter to make ConvNext compatible with YOLO architecture\n",
    "    Converts ConvNext features to YOLO expected format\n",
    "    \"\"\"\n",
    "    def __init__(self, model_name=\"facebook/dinov3-convnext-base-pretrain-lvd1689m\"):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Load the pre-trained ConvNext model\n",
    "        config = DINOv3ConvNextConfig.from_pretrained(model_name)\n",
    "        self.convnext = DINOv3ConvNextModel.from_pretrained(model_name, config=config)\n",
    "        \n",
    "        # Fix: We need to dynamically determine the actual channel sizes\n",
    "        # Test forward pass to get actual dimensions\n",
    "        with torch.no_grad():\n",
    "            test_input = torch.randn(1, 3, 224, 224)\n",
    "            outputs = self.convnext(test_input, output_hidden_states=True)\n",
    "            actual_channels = [feat.shape[1] for feat in outputs.hidden_states]\n",
    "            print(f\"Actual ConvNext channels: {actual_channels}\")\n",
    "        \n",
    "        # Create adaptation layers based on actual channels\n",
    "        self.adapt_layers = nn.ModuleList()\n",
    "        target_channels = [256, 512, 1024]  # YOLO expected channels\n",
    "        \n",
    "        for i in range(min(3, len(actual_channels))):\n",
    "            in_ch = actual_channels[i] if i < len(actual_channels) else actual_channels[-1]\n",
    "            out_ch = target_channels[i]\n",
    "            self.adapt_layers.append(nn.Conv2d(in_ch, out_ch, 1))\n",
    "            \n",
    "        for layer in self.adapt_layers:\n",
    "            nn.init.kaiming_normal_(layer.weight, mode='fan_out', nonlinearity='relu')\n",
    "            nn.init.constant_(layer.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Extract features compatible with YOLO format\n",
    "        Returns [P3, P4, P5] features\n",
    "        \"\"\"\n",
    "        outputs = self.convnext(x, output_hidden_states=True)\n",
    "        hidden_states = outputs.hidden_states  # List of tensors\n",
    "\n",
    "        print(f\"ConvNext hidden_states length: {len(hidden_states)}\")  # Debug\n",
    "\n",
    "        # Fix: Handle the case where we only have 2 hidden states\n",
    "        if len(hidden_states) >= 3:\n",
    "            selected = [hidden_states[0], hidden_states[1], hidden_states[2]]\n",
    "        elif len(hidden_states) == 2:\n",
    "            # Duplicate the last feature map for P5\n",
    "            selected = [hidden_states[0], hidden_states[1], hidden_states[1]]\n",
    "        else:\n",
    "            raise ValueError(f\"ConvNext hidden_states has only {len(hidden_states)} stages, need at least 2 for YOLO neck.\")\n",
    "\n",
    "        features = []\n",
    "        for i, feat in enumerate(selected):\n",
    "            adapted_feature = self.adapt_layers[i](feat)\n",
    "            features.append(adapted_feature)\n",
    "\n",
    "        return features  # [P3, P4, P5]\n",
    "\n",
    "class ConvNextYOLO(nn.Module):\n",
    "    \"\"\"\n",
    "    YOLO model with ConvNext backbone\n",
    "    Uses real YOLO head from ultralytics\n",
    "    \"\"\"\n",
    "    def __init__(self, yolo_model_path=\"yolov8n.pt\", num_classes=2):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Load pretrained YOLO model\n",
    "        self.yolo_model = YOLO(yolo_model_path)\n",
    "        self.yolo_pytorch_model = self.yolo_model.model\n",
    "        \n",
    "        # Replace the backbone with ConvNext\n",
    "        self.convnext_backbone = ConvNextBackboneAdapter()\n",
    "        \n",
    "        # Fix: Better way to extract neck and head\n",
    "        # Get the actual model layers\n",
    "        model_layers = list(self.yolo_pytorch_model.model)\n",
    "        \n",
    "        # Find neck and head indices (usually last few layers)\n",
    "        self.neck = None\n",
    "        self.head = None\n",
    "        \n",
    "        # For YOLOv8, typically:\n",
    "        # - Backbone: layers 0-9\n",
    "        # - Neck: layers 10-18 (FPN/PAN)\n",
    "        # - Head: layer 19+ (Detection head)\n",
    "        \n",
    "        # Extract neck (FPN/PAN layers)\n",
    "        try:\n",
    "            self.neck = nn.Sequential(*model_layers[10:19])  # Adjust indices as needed\n",
    "            self.head = model_layers[-1]  # Detection head\n",
    "        except IndexError:\n",
    "            # Fallback: use simpler approach\n",
    "            self.neck = self.yolo_pytorch_model.model[-2]\n",
    "            self.head = self.yolo_pytorch_model.model[-1]\n",
    "        \n",
    "        # Update head for 2 classes\n",
    "        self._update_head_for_classes(num_classes)\n",
    "    \n",
    "    def _update_head_for_classes(self, num_classes):\n",
    "        \"\"\"Update detection head for custom number of classes\"\"\"\n",
    "        if hasattr(self.head, 'nc'):\n",
    "            self.head.nc = num_classes\n",
    "        \n",
    "        # Update the classification layers\n",
    "        if hasattr(self.head, 'cv3'):  # YOLOv8 style\n",
    "            for i, cv3_layer in enumerate(self.head.cv3):\n",
    "                if hasattr(cv3_layer, '__getitem__') and len(cv3_layer) > 0:\n",
    "                    old_conv = cv3_layer[-1]\n",
    "                    new_conv = nn.Conv2d(\n",
    "                        old_conv.in_channels,\n",
    "                        num_classes,  # Simplified: just num_classes\n",
    "                        old_conv.kernel_size,\n",
    "                        old_conv.stride,\n",
    "                        old_conv.padding,\n",
    "                        bias=old_conv.bias is not None\n",
    "                    )\n",
    "                    cv3_layer[-1] = new_conv\n",
    "    \n",
    "    def forward(self, x):\n",
    "        try:\n",
    "            # Extract features using ConvNext backbone\n",
    "            backbone_features = self.convnext_backbone(x)\n",
    "            \n",
    "            # Ensure we have the right number of features\n",
    "            if len(backbone_features) < 3:\n",
    "                # Pad with the last feature\n",
    "                while len(backbone_features) < 3:\n",
    "                    backbone_features.append(backbone_features[-1])\n",
    "            \n",
    "            # Pass through YOLO neck (FPN)\n",
    "            if self.neck is not None:\n",
    "                neck_features = self.neck(backbone_features)\n",
    "            else:\n",
    "                neck_features = backbone_features\n",
    "            \n",
    "            # Pass through YOLO detection head\n",
    "            detections = self.head(neck_features)\n",
    "            \n",
    "            return detections\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Forward pass error: {e}\")\n",
    "            print(f\"Backbone features shapes: {[f.shape for f in backbone_features]}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5aebde0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Main recommended approach using ultralytics YOLOv8\n",
    "def create_convnext_yolo(yolo_version=\"yolov8n.pt\", num_classes=2):\n",
    "    \"\"\"\n",
    "    Create ConvNext-YOLO model using ultralytics\n",
    "    \"\"\"\n",
    "    print(f\"Creating ConvNext-YOLO with {yolo_version}\")\n",
    "    \n",
    "    # Create the hybrid model\n",
    "    model = ConvNextYOLO(yolo_version, num_classes)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# Training functions using ultralytics API\n",
    "def train_convnext_yolo(model, data_yaml_path, epochs=100, img_size=640, batch_size=16):\n",
    "    \"\"\"\n",
    "    Train the ConvNext-YOLO model\n",
    "    \n",
    "    Args:\n",
    "        model: ConvNextYOLO model\n",
    "        data_yaml_path: Path to YOLO format dataset YAML file\n",
    "        epochs: Number of training epochs\n",
    "        img_size: Input image size\n",
    "        batch_size: Training batch size\n",
    "    \"\"\"\n",
    "    \n",
    "    # For training, we need to create a custom trainer or use ultralytics with modifications\n",
    "    # This is a simplified approach - you might need to modify ultralytics source code\n",
    "    \n",
    "    # Create a temporary YOLO model for training setup\n",
    "    temp_yolo = YOLO(\"yolov8n.pt\")\n",
    "    \n",
    "    # Replace the model's backbone with our ConvNext version\n",
    "    temp_yolo.model = model\n",
    "    \n",
    "    # Train using ultralytics API\n",
    "    results = temp_yolo.train(\n",
    "        data=data_yaml_path,\n",
    "        epochs=epochs,\n",
    "        imgsz=img_size,\n",
    "        batch=batch_size,\n",
    "        name='convnext_yolo_fire_detection',\n",
    "        project='runs/detect',\n",
    "        save_period=10,\n",
    "        device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    )\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "36601358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset YAML for fire/smoke detection\n",
    "def create_fire_smoke_yaml(train_path, val_path, output_path=\"fire_smoke.yaml\"):\n",
    "    \"\"\"\n",
    "    Create YAML configuration file for fire/smoke dataset\n",
    "    \"\"\"\n",
    "    yaml_content = f\"\"\"\n",
    "# Fire and Smoke Detection Dataset Configuration\n",
    "\n",
    "# Train and validation paths\n",
    "train: {train_path}\n",
    "val: {val_path}\n",
    "\n",
    "# Number of classes\n",
    "nc: 2\n",
    "\n",
    "# Class names\n",
    "names:\n",
    "  0: fire\n",
    "  1: smoke\n",
    "\"\"\"\n",
    "    \n",
    "    with open(output_path, 'w') as f:\n",
    "        f.write(yaml_content)\n",
    "    \n",
    "    print(f\"Dataset YAML created at: {output_path}\")\n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7b5332c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_convnext_yolo():\n",
    "    \"\"\"Test the ConvNext-YOLO model with better error handling\"\"\"\n",
    "    print(\"Testing ConvNext-YOLO Model...\")\n",
    "    \n",
    "    try:\n",
    "        # Create model\n",
    "        model = create_convnext_yolo(\"yolov8n.pt\", num_classes=2)\n",
    "        \n",
    "        # Test input - start with smaller size\n",
    "        test_input = torch.randn(1, 3, 224, 224)  # Start with 224x224\n",
    "        \n",
    "        # Forward pass\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            print(f\"Testing with input shape: {test_input.shape}\")\n",
    "            outputs = model(test_input)\n",
    "        \n",
    "        print(f\"✅ Model test successful!\")\n",
    "        print(f\"Input shape: {test_input.shape}\")\n",
    "        print(f\"Output type: {type(outputs)}\")\n",
    "        \n",
    "        if isinstance(outputs, (list, tuple)):\n",
    "            for i, output in enumerate(outputs):\n",
    "                print(f\"Output {i} shape: {output.shape}\")\n",
    "        else:\n",
    "            print(f\"Output shape: {outputs.shape}\")\n",
    "        \n",
    "        return model\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Model test failed: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()  # Print full stack trace\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "49997617",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_fire_smoke(model, image_path, confidence=0.25, save_results=True):\n",
    "    \"\"\"\n",
    "    Predict fire and smoke in an image\n",
    "    \n",
    "    Args:\n",
    "        model: Trained ConvNext-YOLO model\n",
    "        image_path: Path to input image\n",
    "        confidence: Confidence threshold\n",
    "        save_results: Whether to save detection results\n",
    "    \"\"\"\n",
    "    \n",
    "    # For inference, we can use ultralytics API\n",
    "    # Create YOLO object with our custom model\n",
    "    yolo = YOLO(\"yolov8n.pt\")  # Load base\n",
    "    yolo.model = model  # Replace with our model\n",
    "    \n",
    "    # Run inference\n",
    "    results = yolo(image_path, conf=confidence, save=save_results)\n",
    "    \n",
    "    # Process results\n",
    "    for result in results:\n",
    "        boxes = result.boxes\n",
    "        if boxes is not None:\n",
    "            print(f\"Detected {len(boxes)} objects:\")\n",
    "            for box in boxes:\n",
    "                cls = int(box.cls[0])\n",
    "                conf = float(box.conf[0])\n",
    "                class_name = \"fire\" if cls == 0 else \"smoke\"\n",
    "                print(f\"  {class_name}: {conf:.3f}\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "17ab3084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔥 ConvNext-YOLO Fire Detection Setup\n",
      "==================================================\n",
      "Testing ConvNext-YOLO Model...\n",
      "Creating ConvNext-YOLO with yolov8n.pt\n",
      "Actual ConvNext channels: [3, 128, 256, 512, 1024]\n",
      "Ultralytics 8.3.191 🚀 Python-3.12.7 torch-2.8.0+cu128 CPU (13th Gen Intel Core(TM) i7-13700H)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=coco.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/home/abdelrahman-amgad/dev/AI/fire-detection/runs/detect/train, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "\n",
      "WARNING ⚠️ Dataset 'coco.yaml' images not found, missing path '/home/abdelrahman-amgad/dev/AI/datasets/coco/val2017.txt'\n",
      "\u001b[KDownloading https://ultralytics.com/assets/coco2017labels-segments.zip to '/home/abdelrahman-amgad/dev/AI/datasets/coco2017labels-segments.zip': 28% ━━━───────── 47.4/168.5MB 402.2KB/s 24.5s<5:08\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m50\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Test model creation\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m model = \u001b[43mtest_convnext_yolo\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m      9\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m📊 Model Information:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mtest_convnext_yolo\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     10\u001b[39m test_input = torch.randn(\u001b[32m1\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m224\u001b[39m, \u001b[32m224\u001b[39m)  \u001b[38;5;66;03m# Start with 224x224\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m     15\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTesting with input shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_input.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/AI/fire-detection/myenv/lib/python3.12/site-packages/torch/nn/modules/module.py:2905\u001b[39m, in \u001b[36mModule.eval\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2889\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34meval\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Self:\n\u001b[32m   2890\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Set the module in evaluation mode.\u001b[39;00m\n\u001b[32m   2891\u001b[39m \n\u001b[32m   2892\u001b[39m \u001b[33;03m    This has an effect only on certain modules. See the documentation of\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2903\u001b[39m \u001b[33;03m        Module: self\u001b[39;00m\n\u001b[32m   2904\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2905\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/AI/fire-detection/myenv/lib/python3.12/site-packages/torch/nn/modules/module.py:2886\u001b[39m, in \u001b[36mModule.train\u001b[39m\u001b[34m(self, mode)\u001b[39m\n\u001b[32m   2884\u001b[39m \u001b[38;5;28mself\u001b[39m.training = mode\n\u001b[32m   2885\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m-> \u001b[39m\u001b[32m2886\u001b[39m     \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2887\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/AI/fire-detection/myenv/lib/python3.12/site-packages/ultralytics/engine/model.py:795\u001b[39m, in \u001b[36mModel.train\u001b[39m\u001b[34m(self, trainer, **kwargs)\u001b[39m\n\u001b[32m    792\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m args.get(\u001b[33m\"\u001b[39m\u001b[33mresume\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    793\u001b[39m     args[\u001b[33m\"\u001b[39m\u001b[33mresume\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m.ckpt_path\n\u001b[32m--> \u001b[39m\u001b[32m795\u001b[39m \u001b[38;5;28mself\u001b[39m.trainer = \u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_smart_load\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrainer\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43moverrides\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_callbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args.get(\u001b[33m\"\u001b[39m\u001b[33mresume\u001b[39m\u001b[33m\"\u001b[39m):  \u001b[38;5;66;03m# manually set model only if not resuming\u001b[39;00m\n\u001b[32m    797\u001b[39m     \u001b[38;5;28mself\u001b[39m.trainer.model = \u001b[38;5;28mself\u001b[39m.trainer.get_model(weights=\u001b[38;5;28mself\u001b[39m.model \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ckpt \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, cfg=\u001b[38;5;28mself\u001b[39m.model.yaml)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/AI/fire-detection/myenv/lib/python3.12/site-packages/ultralytics/engine/trainer.py:154\u001b[39m, in \u001b[36mBaseTrainer.__init__\u001b[39m\u001b[34m(self, cfg, overrides, _callbacks)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;28mself\u001b[39m.model = check_model_file_from_stem(\u001b[38;5;28mself\u001b[39m.args.model)  \u001b[38;5;66;03m# add suffix, i.e. yolo11n -> yolo11n.pt\u001b[39;00m\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch_distributed_zero_first(LOCAL_RANK):  \u001b[38;5;66;03m# avoid auto-downloading dataset multiple times\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m     \u001b[38;5;28mself\u001b[39m.data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[38;5;28mself\u001b[39m.ema = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    158\u001b[39m \u001b[38;5;66;03m# Optimization utils init\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/AI/fire-detection/myenv/lib/python3.12/site-packages/ultralytics/engine/trainer.py:623\u001b[39m, in \u001b[36mBaseTrainer.get_dataset\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    616\u001b[39m     data = check_det_dataset(\u001b[38;5;28mself\u001b[39m.args.data)\n\u001b[32m    617\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.data.rsplit(\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m1\u001b[39m)[-\u001b[32m1\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33myaml\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33myml\u001b[39m\u001b[33m\"\u001b[39m} \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.task \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[32m    618\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mdetect\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    619\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33msegment\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    620\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mpose\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    621\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mobb\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    622\u001b[39m }:\n\u001b[32m--> \u001b[39m\u001b[32m623\u001b[39m     data = \u001b[43mcheck_det_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    624\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33myaml_file\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[32m    625\u001b[39m         \u001b[38;5;28mself\u001b[39m.args.data = data[\u001b[33m\"\u001b[39m\u001b[33myaml_file\u001b[39m\u001b[33m\"\u001b[39m]  \u001b[38;5;66;03m# for validating 'yolo train data=url.zip' usage\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/AI/fire-detection/myenv/lib/python3.12/site-packages/ultralytics/data/utils.py:476\u001b[39m, in \u001b[36mcheck_det_dataset\u001b[39m\u001b[34m(dataset, autodownload)\u001b[39m\n\u001b[32m    474\u001b[39m     subprocess.run(s.split(), check=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    475\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# python script\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m476\u001b[39m     \u001b[43mexec\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43myaml\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    477\u001b[39m dt = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(time.time()\u001b[38;5;250m \u001b[39m-\u001b[38;5;250m \u001b[39mt,\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33ms)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    478\u001b[39m s = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33msuccess ✅ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdt\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcolorstr(\u001b[33m'\u001b[39m\u001b[33mbold\u001b[39m\u001b[33m'\u001b[39m,\u001b[38;5;250m \u001b[39mDATASETS_DIR)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m} \u001b[38;5;28;01melse\u001b[39;00m \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mfailure \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdt\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ❌\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:10\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/AI/fire-detection/myenv/lib/python3.12/site-packages/ultralytics/utils/downloads.py:541\u001b[39m, in \u001b[36mdownload\u001b[39m\u001b[34m(url, dir, unzip, delete, curl, threads, retry, exist_ok)\u001b[39m\n\u001b[32m    539\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    540\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m u \u001b[38;5;129;01min\u001b[39;00m urls:\n\u001b[32m--> \u001b[39m\u001b[32m541\u001b[39m         \u001b[43msafe_download\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdir\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mdir\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munzip\u001b[49m\u001b[43m=\u001b[49m\u001b[43munzip\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelete\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdelete\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurl\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcurl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/AI/fire-detection/myenv/lib/python3.12/site-packages/ultralytics/utils/downloads.py:356\u001b[39m, in \u001b[36msafe_download\u001b[39m\u001b[34m(url, file, dir, unzip, delete, curl, retry, min_bytes, exist_ok, progress)\u001b[39m\n\u001b[32m    354\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(f, \u001b[33m\"\u001b[39m\u001b[33mwb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f_opened:\n\u001b[32m    355\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m356\u001b[39m         data = \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    357\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[32m    358\u001b[39m             \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/http/client.py:479\u001b[39m, in \u001b[36mHTTPResponse.read\u001b[39m\u001b[34m(self, amt)\u001b[39m\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.length \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt > \u001b[38;5;28mself\u001b[39m.length:\n\u001b[32m    477\u001b[39m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[32m    478\u001b[39m     amt = \u001b[38;5;28mself\u001b[39m.length\n\u001b[32m--> \u001b[39m\u001b[32m479\u001b[39m s = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[32m    481\u001b[39m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[32m    482\u001b[39m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[32m    483\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_conn()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/socket.py:720\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    719\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m720\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    721\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    722\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/ssl.py:1251\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1247\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1248\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1249\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1250\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1251\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1252\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1253\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/ssl.py:1103\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1101\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1102\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1103\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1104\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1105\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"🔥 ConvNext-YOLO Fire Detection Setup\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Test model creation\n",
    "    model = test_convnext_yolo()\n",
    "    \n",
    "    if model is not None:\n",
    "        print(f\"\\n📊 Model Information:\")\n",
    "        total_params = sum(p.numel() for p in model.parameters())\n",
    "        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "        print(f\"Total parameters: {total_params:,}\")\n",
    "        print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "        \n",
    "        print(f\"\\n🏗️ Architecture:\")\n",
    "        print(f\"Backbone: ConvNext (DINOv3) - Pre-trained\")\n",
    "        print(f\"Neck: YOLO FPN - From ultralytics\") \n",
    "        print(f\"Head: YOLO Detection Head - From ultralytics\")\n",
    "        print(f\"Classes: Fire (0), Smoke (1)\")\n",
    "        \n",
    "        print(f\"\\n📋 Next Steps:\")\n",
    "        print(f\"1. Prepare your dataset in YOLO format\")\n",
    "        print(f\"2. Create dataset YAML using create_fire_smoke_yaml()\")\n",
    "        print(f\"3. Train using train_convnext_yolo()\")\n",
    "        print(f\"4. Use predict_fire_smoke() for inference\")\n",
    "        \n",
    "        # Example dataset setup\n",
    "        print(f\"\\n💡 Example dataset setup:\")\n",
    "        print(f\"# Create YAML config\")\n",
    "        print(f\"yaml_path = create_fire_smoke_yaml('path/to/train', 'path/to/val')\")\n",
    "        print(f\"\")\n",
    "        print(f\"# Train model\") \n",
    "        print(f\"results = train_convnext_yolo(model, yaml_path, epochs=100)\")\n",
    "        print(f\"\")\n",
    "        print(f\"# Inference\")\n",
    "        print(f\"predictions = predict_fire_smoke(model, 'test_image.jpg')\")\n",
    "        \n",
    "    else:\n",
    "        print(\"\\n❌ Please install required dependencies:\")\n",
    "        print(\"pip install ultralytics\")\n",
    "        print(\"# or for YOLOv5:\")\n",
    "        print(\"pip install yolov5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
