{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11741902,"sourceType":"datasetVersion","datasetId":7370967}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install ultralytics","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T23:12:23.409285Z","iopub.execute_input":"2025-09-10T23:12:23.409564Z","iopub.status.idle":"2025-09-10T23:13:53.281737Z","shell.execute_reply.started":"2025-09-10T23:12:23.409538Z","shell.execute_reply":"2025-09-10T23:13:53.280845Z"}},"outputs":[{"name":"stdout","text":"Collecting ultralytics\n  Downloading ultralytics-8.3.198-py3-none-any.whl.metadata (37 kB)\nRequirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.26.4)\nRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.7.2)\nRequirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\nRequirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.2.1)\nRequirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\nRequirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.4)\nRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.15.3)\nRequirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\nRequirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (7.0.0)\nRequirement already satisfied: polars in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.21.0)\nCollecting ultralytics-thop>=2.0.0 (from ultralytics)\n  Downloading ultralytics_thop-2.0.17-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.58.4)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.6.15)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.5.1)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.0->ultralytics) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.0->ultralytics) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.23.0->ultralytics) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.23.0->ultralytics) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.23.0->ultralytics) (2024.2.0)\nDownloading ultralytics-8.3.198-py3-none-any.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading ultralytics_thop-2.0.17-py3-none-any.whl (28 kB)\nInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\nSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.198 ultralytics-thop-2.0.17\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport glob\nimport random\nfrom pathlib import Path\n\nimport cv2\nimport numpy as np\nfrom PIL import Image\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom ultralytics import YOLO\nfrom ultralytics.models.yolo.detect.train import DetectionTrainer\nfrom ultralytics.utils.loss import v8DetectionLoss\n\nfrom types import SimpleNamespace","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T23:39:11.315261Z","iopub.execute_input":"2025-09-10T23:39:11.315789Z","iopub.status.idle":"2025-09-10T23:39:11.320574Z","shell.execute_reply.started":"2025-09-10T23:39:11.315764Z","shell.execute_reply":"2025-09-10T23:39:11.319851Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# Official Facebook ConvNext Implementation\nclass DropPath(nn.Module):\n    def __init__(self, drop_prob=None):\n        super(DropPath, self).__init__()\n        self.drop_prob = drop_prob\n\n    def forward(self, x):\n        if self.drop_prob == 0. or not self.training:\n            return x\n        keep_prob = 1 - self.drop_prob\n        shape = (x.shape[0],) + (1,) * (x.ndim - 1)\n        random_tensor = keep_prob + torch.rand(shape, dtype=x.dtype, device=x.device)\n        random_tensor.floor_()\n        output = x.div(keep_prob) * random_tensor\n        return output\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T23:39:14.830015Z","iopub.execute_input":"2025-09-10T23:39:14.830291Z","iopub.status.idle":"2025-09-10T23:39:14.835335Z","shell.execute_reply.started":"2025-09-10T23:39:14.830271Z","shell.execute_reply":"2025-09-10T23:39:14.834672Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"class LayerNorm(nn.Module):\n    def __init__(self, normalized_shape, eps=1e-6, data_format=\"channels_last\"):\n        super().__init__()\n        self.weight = nn.Parameter(torch.ones(normalized_shape))\n        self.bias = nn.Parameter(torch.zeros(normalized_shape))\n        self.eps = eps\n        self.data_format = data_format\n        if self.data_format not in [\"channels_last\", \"channels_first\"]:\n            raise NotImplementedError \n        self.normalized_shape = (normalized_shape, )\n    \n    def forward(self, x):\n        if self.data_format == \"channels_last\":\n            return F.layer_norm(x, self.normalized_shape, self.weight, self.bias, self.eps)\n        elif self.data_format == \"channels_first\":\n            u = x.mean(1, keepdim=True)\n            s = (x - u).pow(2).mean(1, keepdim=True)\n            x = (x - u) / torch.sqrt(s + self.eps)\n            x = self.weight[:, None, None] * x + self.bias[:, None, None]\n            return x\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T23:39:16.821990Z","iopub.execute_input":"2025-09-10T23:39:16.822739Z","iopub.status.idle":"2025-09-10T23:39:16.828417Z","shell.execute_reply.started":"2025-09-10T23:39:16.822717Z","shell.execute_reply":"2025-09-10T23:39:16.827686Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"class Block(nn.Module):\n    def __init__(self, dim, drop_path=0., layer_scale_init_value=1e-6):\n        super().__init__()\n        self.dwconv = nn.Conv2d(dim, dim, kernel_size=7, padding=3, groups=dim)\n        self.norm = LayerNorm(dim, eps=1e-6)\n        self.pwconv1 = nn.Linear(dim, 4 * dim)\n        self.act = nn.GELU()\n        self.pwconv2 = nn.Linear(4 * dim, dim)\n        self.gamma = nn.Parameter(layer_scale_init_value * torch.ones((dim)), \n                                    requires_grad=True) if layer_scale_init_value > 0 else None\n        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n\n    def forward(self, x):\n        input = x\n        x = self.dwconv(x)\n        x = x.permute(0, 2, 3, 1)  # (N, C, H, W) -> (N, H, W, C)\n        x = self.norm(x)\n        x = self.pwconv1(x)\n        x = self.act(x)\n        x = self.pwconv2(x)\n        if self.gamma is not None:\n            x = self.gamma * x\n        x = x.permute(0, 3, 1, 2)  # (N, H, W, C) -> (N, C, H, W)\n        x = input + self.drop_path(x)\n        return x\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T23:39:19.206743Z","iopub.execute_input":"2025-09-10T23:39:19.207004Z","iopub.status.idle":"2025-09-10T23:39:19.213622Z","shell.execute_reply.started":"2025-09-10T23:39:19.206986Z","shell.execute_reply":"2025-09-10T23:39:19.212853Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"\nclass ConvNeXt(nn.Module):\n    def __init__(self, in_chans=3, num_classes=1000, \n                 depths=[3, 3, 9, 3], dims=[96, 192, 384, 768], drop_path_rate=0., \n                 layer_scale_init_value=1e-6, head_init_scale=1.):\n        super().__init__()\n\n        self.downsample_layers = nn.ModuleList()\n        stem = nn.Sequential(\n            nn.Conv2d(in_chans, dims[0], kernel_size=4, stride=4),\n            LayerNorm(dims[0], eps=1e-6, data_format=\"channels_first\")\n        )\n        self.downsample_layers.append(stem)\n        \n        for i in range(3):\n            downsample_layer = nn.Sequential(\n                    LayerNorm(dims[i], eps=1e-6, data_format=\"channels_first\"),\n                    nn.Conv2d(dims[i], dims[i+1], kernel_size=2, stride=2),\n            )\n            self.downsample_layers.append(downsample_layer)\n\n        self.stages = nn.ModuleList()\n        dp_rates=[x.item() for x in torch.linspace(0, drop_path_rate, sum(depths))] \n        cur = 0\n        for i in range(4):\n            stage = nn.Sequential(\n                *[Block(dim=dims[i], drop_path=dp_rates[cur + j], \n                layer_scale_init_value=layer_scale_init_value) for j in range(depths[i])]\n            )\n            self.stages.append(stage)\n            cur += depths[i]\n\n        self.norm = nn.LayerNorm(dims[-1], eps=1e-6)\n        self.head = nn.Linear(dims[-1], num_classes)\n\n        self.apply(self._init_weights)\n        self.head.weight.data.mul_(head_init_scale)\n        self.head.bias.data.mul_(head_init_scale)\n\n    def _init_weights(self, m):\n        if isinstance(m, (nn.Conv2d, nn.Linear)):\n            nn.init.trunc_normal_(m.weight, std=.02)\n            nn.init.constant_(m.bias, 0)\n\n    def forward_features(self, x):\n        features = []\n        for i in range(4):\n            x = self.downsample_layers[i](x)\n            x = self.stages[i](x)\n            features.append(x)\n        return features\n\n    def forward(self, x):\n        features = self.forward_features(x)\n        x = self.norm(features[-1].mean([-2, -1]))  # global average pooling\n        x = self.head(x)\n        return x\n\ndef convnext_tiny(pretrained=False, weights_path=None, **kwargs):\n    \"\"\"ConvNext Tiny model\"\"\"\n    model = ConvNeXt(depths=[3, 3, 9, 3], dims=[96, 192, 384, 768], **kwargs)\n    \n    if pretrained and weights_path:\n        print(f\"🔄 Loading pretrained weights from {weights_path}\")\n        checkpoint = torch.load(weights_path, map_location=\"cpu\")\n        \n        # Handle different checkpoint formats\n        if \"model\" in checkpoint:\n            state_dict = checkpoint[\"model\"]\n        else:\n            state_dict = checkpoint\n            \n        model.load_state_dict(state_dict)\n        print(\"✅ Pretrained weights loaded successfully!\")\n    elif pretrained:\n        print(\"⚠️ Pretrained=True but no weights_path provided\")\n        \n    return model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T23:39:22.446842Z","iopub.execute_input":"2025-09-10T23:39:22.447111Z","iopub.status.idle":"2025-09-10T23:39:22.458538Z","shell.execute_reply.started":"2025-09-10T23:39:22.447091Z","shell.execute_reply":"2025-09-10T23:39:22.457980Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"class ConvNextBackbone(nn.Module):\n    \"\"\"ConvNext backbone optimized for YOLO integration\"\"\"\n    \n    def __init__(self, weights_path=None, pretrained=True):\n        super().__init__()\n        \n        # Create ConvNext Tiny with official architecture\n        self.convnext = convnext_tiny(pretrained=pretrained, weights_path=weights_path)\n        \n        # Remove classification head (we only need features)\n        self.convnext.norm = nn.Identity()\n        self.convnext.head = nn.Identity()\n        \n        # ConvNext Tiny feature dimensions: [96, 192, 384, 768]\n        self.feature_dims = [192, 384, 768]  # Last 3 stages for multi-scale detection\n        target_dims = [256, 512, 1024]       # YOLO expected channels\n        \n        # Feature adaptation layers\n        self.adapters = nn.ModuleList([\n            nn.Sequential(\n                nn.Conv2d(in_dim, out_dim, 1, bias=False),\n                nn.BatchNorm2d(out_dim),\n                nn.ReLU(inplace=True)\n            ) for in_dim, out_dim in zip(self.feature_dims, target_dims)\n        ])\n        \n        print(\"✅ ConvNext Tiny backbone ready for YOLO integration\")\n        print(f\"📊 Feature channels: {self.feature_dims} → {target_dims}\")\n\n    def forward(self, x):\n        # Extract multi-scale features from ConvNext\n        features = self.convnext.forward_features(x)\n        \n        # Take last 3 feature maps: [Stage1: 192ch, Stage2: 384ch, Stage3: 768ch]\n        selected_features = features[-3:]\n        \n        # Adapt to YOLO expected channels\n        adapted_features = []\n        for feat, adapter in zip(selected_features, self.adapters):\n            adapted_feat = adapter(feat)\n            adapted_features.append(adapted_feat)\n        \n        return adapted_features\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T23:39:26.021227Z","iopub.execute_input":"2025-09-10T23:39:26.021494Z","iopub.status.idle":"2025-09-10T23:39:26.028270Z","shell.execute_reply.started":"2025-09-10T23:39:26.021474Z","shell.execute_reply":"2025-09-10T23:39:26.027430Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"\ndef download_convnext_weights(model_name=\"convnext_tiny_1k\"):\n    \"\"\"Download ConvNext weights if not present\"\"\"\n    model_urls = {\n        \"convnext_tiny_1k\": \"https://dl.fbaipublicfiles.com/convnext/convnext_tiny_1k_224_ema.pth\",\n        \"convnext_tiny_22k\": \"https://dl.fbaipublicfiles.com/convnext/convnext_tiny_22k_224.pth\",\n    }\n    \n    weights_file = f\"{model_name}.pth\"\n    \n    if os.path.exists(weights_file):\n        print(f\"✅ Found existing weights: {weights_file}\")\n        return weights_file\n    \n    if model_name in model_urls:\n        print(f\"📥 Downloading {model_name} weights...\")\n        checkpoint = torch.hub.load_state_dict_from_url(\n            url=model_urls[model_name], \n            map_location=\"cpu\", \n            file_name=weights_file\n        )\n        # Save to current directory for future use\n        torch.save(checkpoint, weights_file)\n        print(f\"✅ Downloaded and saved: {weights_file}\")\n        return weights_file\n    else:\n        print(f\"❌ Unknown model: {model_name}\")\n        return None\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-10T23:39:29.167070Z","iopub.execute_input":"2025-09-10T23:39:29.167363Z","iopub.status.idle":"2025-09-10T23:39:29.172712Z","shell.execute_reply.started":"2025-09-10T23:39:29.167344Z","shell.execute_reply":"2025-09-10T23:39:29.171914Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom ultralytics import YOLO\n\n\nclass WorkingConvNextYOLO(nn.Module):\n    \"\"\"Working YOLO model with ConvNeXt backbone - fixed iteration issues\"\"\"\n    \n    def __init__(self, yolo_path=\"yolov8n.pt\", num_classes=2, convnext_weights_path=None, freeze_backbone=True, hyp=None):\n        super().__init__()\n        self.hyp = hyp\n        self.args = SimpleNamespace(hyp=self.hyp)\n        print(f\"Creating Working ConvNext-YOLO...\")\n        \n        # Load YOLO and get the underlying model\n        yolo_wrapper = YOLO(\"yolov8n.pt\")\n        self.yolo = yolo_wrapper.model  # This is the DetectionModel\n        self.head = self.yolo.model[-1]\n        self.stride = self.head.stride \n        print(f\"Original YOLO type: {type(self.yolo)}\")\n        \n        # Access the model's sequential layers properly\n        if hasattr(self.yolo, 'model'):\n            model_layers = self.yolo.model  # This should be the sequential part\n            print(f\"Model layers type: {type(model_layers)}\")\n            print(f\"Number of layers: {len(model_layers) if hasattr(model_layers, '__len__') else 'Unknown'}\")\n        \n        # Replace backbone\n        print(\"Replacing backbone with ConvNeXt...\")\n        #original_backbone = self.yolo.backbone\n        self.yolo.backbone = ConvNextBackbone(\n            weights_path=convnext_weights_path,\n            pretrained=True if convnext_weights_path else False\n        )\n        print(\"swapped\")\n        \n        # Freeze backbone if requested\n        if freeze_backbone:\n            print(\"Freezing ConvNeXt backbone...\")\n            for param in self.yolo.backbone.parameters():\n                param.requires_grad = False\n        \n        # Update detection head\n        self._update_detection_head(num_classes)\n        \n        # Ensure neck and head are trainable\n        self._ensure_trainable_components()\n        \n        self._print_summary()\n        \n        self.model = nn.Sequential(\n            *list(self.yolo.model[:-1]),  # backbone\n            self.yolo.model[-1]           # detection head\n        )\n        self.model.args=self.args \n    \n    def _update_detection_head(self, num_classes):\n        \"\"\"Update detection head for new classes\"\"\"\n        print(f\"Updating detection head: -> {num_classes} classes\")\n        \n        # Find the Detect layer - it's usually the last layer in the model\n        detect_layer = None\n        if hasattr(self.yolo, 'model'):\n            # Try to get the last layer\n            if hasattr(self.yolo.model, '__getitem__'):\n                detect_layer = self.yolo.model[-1]\n            else:\n                # Fallback: search through all modules\n                for module in self.yolo.modules():\n                    if hasattr(module, 'nc') and hasattr(module, 'cv2'):\n                        detect_layer = module\n                        break\n        \n        if detect_layer is None:\n            print(\"Warning: Could not find detection layer!\")\n            return\n        \n        print(f\"Found detection layer: {type(detect_layer)}\")\n        \n        # Update detection layer properties\n        old_nc = getattr(detect_layer, 'nc', 80)\n        detect_layer.nc = num_classes\n        detect_layer.no = num_classes + detect_layer.reg_max * 4\n        \n        # Update classification heads (cv2)\n        if hasattr(detect_layer, 'cv2'):\n            for i, cv2_layer in enumerate(detect_layer.cv2):\n                if hasattr(cv2_layer, '__getitem__') and len(cv2_layer) > 0:\n                    # Get the last conv layer in the cv2 sequence\n                    last_conv = cv2_layer[-1]\n                    if isinstance(last_conv, nn.Conv2d):\n                        in_channels = last_conv.in_channels\n                        # Replace with new conv layer for correct number of classes\n                        cv2_layer[-1] = nn.Conv2d(in_channels, num_classes, 1, bias=True)\n                        print(f\"  Updated cv2[{i}]: {in_channels} -> {num_classes}\")\n        \n        # Update regression heads (cv3) - these stay the same\n        if hasattr(detect_layer, 'cv3'):\n            for i, cv3_layer in enumerate(detect_layer.cv3):\n                if hasattr(cv3_layer, '__getitem__') and len(cv3_layer) > 0:\n                    last_conv = cv3_layer[-1]\n                    if isinstance(last_conv, nn.Conv2d):\n                        in_channels = last_conv.in_channels\n                        cv3_layer[-1] = nn.Conv2d(in_channels, 4 * detect_layer.reg_max, 1, bias=True)\n                        print(f\"  Updated cv3[{i}]: {in_channels} -> {4 * detect_layer.reg_max}\")\n    \n    def _ensure_trainable_components(self):\n        \"\"\"Ensure neck and head components are trainable\"\"\"\n        print(\"Ensuring neck and head are trainable...\")\n        \n        # Method 1: Unfreeze all non-backbone parameters\n        for name, module in self.yolo.named_children():\n            if name != 'backbone':\n                for param in module.parameters():\n                    param.requires_grad = True\n        \n        # Method 2: Specifically unfreeze detection layer\n        for module in self.yolo.modules():\n            if hasattr(module, 'nc') and hasattr(module, 'cv2'):  # This is Detect layer\n                for param in module.parameters():\n                    param.requires_grad = True\n                break\n        \n        # Method 3: If model has sequential structure, unfreeze specific indices\n        if hasattr(self.yolo, 'model') and hasattr(self.yolo.model, '__getitem__'):\n            try:\n                # Typical YOLOv8 structure: backbone is index 0, neck/head are later indices\n                model_layers = self.yolo.model\n                for i in range(1, len(model_layers)):  # Skip index 0 (backbone)\n                    for param in model_layers[i].parameters():\n                        param.requires_grad = True\n            except Exception as e:\n                print(f\"Could not iterate through model layers: {e}\")\n    \n    def _print_summary(self):\n        \"\"\"Print parameter summary\"\"\"\n        total = sum(p.numel() for p in self.parameters())\n        trainable = sum(p.numel() for p in self.parameters() if p.requires_grad)\n        frozen = total - trainable\n        \n        print(f\"\\nParameter Summary:\")\n        print(f\"  Total: {total:,} ({total/1e6:.1f}M)\")\n        print(f\"  Trainable: {trainable:,} ({trainable/1e6:.1f}M)\")\n        print(f\"  Frozen: {frozen:,} ({frozen/1e6:.1f}M)\")\n        print(f\"  Trainable Ratio: {trainable/total*100:.1f}%\")\n        \n        # Component breakdown\n        print(f\"\\nComponent Breakdown:\")\n        if hasattr(self.yolo, 'backbone'):\n            bb_total = sum(p.numel() for p in self.yolo.backbone.parameters())\n            bb_trainable = sum(p.numel() for p in self.yolo.backbone.parameters() if p.requires_grad)\n            print(f\"  Backbone: {bb_total:,} total, {bb_trainable:,} trainable\")\n        \n        # Count detection layer parameters\n        for module in self.yolo.modules():\n            if hasattr(module, 'nc') and hasattr(module, 'cv2'):\n                det_total = sum(p.numel() for p in module.parameters())\n                det_trainable = sum(p.numel() for p in module.parameters() if p.requires_grad)\n                print(f\"  Detection Head: {det_total:,} total, {det_trainable:,} trainable\")\n                break\n                \n    def init_criterion(self):\n        \"\"\"Initialize the loss function.\"\"\"\n        from ultralytics.utils.loss import v8DetectionLoss\n        self.criterion = v8DetectionLoss(self)  # reads hyp from self.args.hyp\n        return self.criterion\n        \n    def forward(self, x):\n        return self.yolo(x)\n\ndef test_working_model():\n    \"\"\"Test the working model\"\"\"\n    print(\"Testing Working ConvNext-YOLO...\")\n    \n    try:\n        # Download weights\n        weights_path = download_convnext_weights(\"convnext_tiny_1k\")\n        \n        # Create model\n        model = WorkingConvNextYOLO(\n            yolo_path=\"yolov8n.pt\",\n            num_classes=2,\n            convnext_weights_path=weights_path,\n            freeze_backbone=True\n        )\n        \n        # Test forward pass\n        print(\"\\nTesting forward pass...\")\n        test_input = torch.randn(1, 3, 640, 640)\n        \n        if torch.cuda.is_available():\n            model = model.cuda()\n            test_input = test_input.cuda()\n        \n        model.eval()\n        with torch.no_grad():\n            output = model(test_input)\n        \n        print(\"Forward pass successful!\")\n        \n        # Analyze output\n        if isinstance(output, (list, tuple)):\n            print(f\"Output: {len(output)} elements\")\n            for i, out in enumerate(output):\n                if hasattr(out, 'shape'):\n                    print(f\"  [{i}]: {out.shape}\")\n                else:\n                    print(f\"  [{i}]: {type(out)}\")\n        else:\n            print(f\"Output shape: {output.shape}\")\n        \n        return model\n        \n    except Exception as e:\n        print(f\"Error: {e}\")\n        import traceback\n        traceback.print_exc()\n        return None\n\ndef debug_yolo_structure(yolo_path=\"yolov8n.pt\"):\n    \"\"\"Debug YOLO model structure\"\"\"\n    print(\"Debugging YOLO structure...\")\n    \n    yolo = YOLO(yolo_path)\n    model = yolo.model\n    \n    print(f\"YOLO wrapper type: {type(yolo)}\")\n    print(f\"Model type: {type(model)}\")\n    print(f\"Model attributes: {dir(model)}\")\n    \n    if hasattr(model, 'model'):\n        inner_model = model.model\n        print(f\"Inner model type: {type(inner_model)}\")\n        if hasattr(inner_model, '__len__'):\n            print(f\"Inner model length: {len(inner_model)}\")\n            for i, layer in enumerate(inner_model):\n                print(f\"  Layer {i}: {type(layer).__name__}\")\n                if i > 10:  # Don't print too many\n                    print(f\"  ... and {len(inner_model) - i - 1} more layers\")\n                    break\n    \n    if hasattr(model, 'backbone'):\n        print(f\"Backbone type: {type(model.backbone)}\")\n    \n    # Look for detection layer\n    for i, module in enumerate(model.modules()):\n        if hasattr(module, 'nc') and hasattr(module, 'cv2'):\n            print(f\"Found Detect layer at module {i}: nc={module.nc}\")\n            break\n\n\n\n\nif __name__ == \"__main__\":\n    # Debug first\n    debug_yolo_structure()\n    \n    print(\"\\n\" + \"=\"*60)\n    \n    # Test working model\n    model = test_working_model()\n    \n    if model:\n        # Run parameter analysis\n        print(\"yes\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T23:39:31.425266Z","iopub.execute_input":"2025-09-10T23:39:31.425532Z","iopub.status.idle":"2025-09-10T23:39:32.755491Z","shell.execute_reply.started":"2025-09-10T23:39:31.425514Z","shell.execute_reply":"2025-09-10T23:39:32.754752Z"}},"outputs":[{"name":"stdout","text":"Debugging YOLO structure...\nYOLO wrapper type: <class 'ultralytics.models.yolo.model.YOLO'>\nModel type: <class 'ultralytics.nn.tasks.DetectionModel'>\nModel attributes: ['T_destination', '__annotations__', '__call__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_apply', '_backward_hooks', '_backward_pre_hooks', '_buffers', '_call_impl', '_clip_augmented', '_compiled_call_impl', '_descale_pred', '_forward_hooks', '_forward_hooks_always_called', '_forward_hooks_with_kwargs', '_forward_pre_hooks', '_forward_pre_hooks_with_kwargs', '_get_backward_hooks', '_get_backward_pre_hooks', '_get_name', '_is_full_backward_hook', '_load_from_state_dict', '_load_state_dict_post_hooks', '_load_state_dict_pre_hooks', '_maybe_warn_non_full_backward_hook', '_modules', '_named_members', '_non_persistent_buffers_set', '_parameters', '_predict_augment', '_predict_once', '_profile_one_layer', '_register_load_state_dict_pre_hook', '_register_state_dict_hook', '_replicate_for_data_parallel', '_save_to_state_dict', '_slow_forward', '_state_dict_hooks', '_state_dict_pre_hooks', '_version', '_wrapped_call_impl', 'add_module', 'apply', 'args', 'bfloat16', 'buffers', 'call_super_init', 'children', 'compile', 'cpu', 'cuda', 'double', 'dump_patches', 'eval', 'extra_repr', 'float', 'forward', 'fuse', 'get_buffer', 'get_extra_state', 'get_parameter', 'get_submodule', 'half', 'info', 'init_criterion', 'inplace', 'ipu', 'is_fused', 'load', 'load_state_dict', 'loss', 'model', 'modules', 'mtia', 'named_buffers', 'named_children', 'named_modules', 'named_parameters', 'names', 'nc', 'parameters', 'predict', 'pt_path', 'register_backward_hook', 'register_buffer', 'register_forward_hook', 'register_forward_pre_hook', 'register_full_backward_hook', 'register_full_backward_pre_hook', 'register_load_state_dict_post_hook', 'register_load_state_dict_pre_hook', 'register_module', 'register_parameter', 'register_state_dict_post_hook', 'register_state_dict_pre_hook', 'requires_grad_', 'save', 'set_extra_state', 'set_submodule', 'share_memory', 'state_dict', 'stride', 'task', 'to', 'to_empty', 'train', 'training', 'type', 'xpu', 'yaml', 'yaml_file', 'zero_grad']\nInner model type: <class 'torch.nn.modules.container.Sequential'>\nInner model length: 23\n  Layer 0: Conv\n  Layer 1: Conv\n  Layer 2: C2f\n  Layer 3: Conv\n  Layer 4: C2f\n  Layer 5: Conv\n  Layer 6: C2f\n  Layer 7: Conv\n  Layer 8: C2f\n  Layer 9: SPPF\n  Layer 10: Upsample\n  Layer 11: Concat\n  ... and 11 more layers\nFound Detect layer at module 172: nc=80\n\n============================================================\nTesting Working ConvNext-YOLO...\n✅ Found existing weights: convnext_tiny_1k.pth\nCreating Working ConvNext-YOLO...\nOriginal YOLO type: <class 'ultralytics.nn.tasks.DetectionModel'>\nModel layers type: <class 'torch.nn.modules.container.Sequential'>\nNumber of layers: 23\nReplacing backbone with ConvNeXt...\n🔄 Loading pretrained weights from convnext_tiny_1k.pth\n✅ Pretrained weights loaded successfully!\n✅ ConvNext Tiny backbone ready for YOLO integration\n📊 Feature channels: [192, 384, 768] → [256, 512, 1024]\nswapped\nFreezing ConvNeXt backbone...\nUpdating detection head: -> 2 classes\nFound detection layer: <class 'ultralytics.nn.modules.head.Detect'>\n  Updated cv2[0]: 64 -> 2\n  Updated cv2[1]: 64 -> 2\n  Updated cv2[2]: 64 -> 2\n  Updated cv3[0]: 80 -> 64\n  Updated cv3[1]: 80 -> 64\n  Updated cv3[2]: 80 -> 64\nEnsuring neck and head are trainable...\n\nParameter Summary:\n  Total: 31,995,590 (32.0M)\n  Trainable: 3,141,222 (3.1M)\n  Frozen: 28,854,368 (28.9M)\n  Trainable Ratio: 9.8%\n\nComponent Breakdown:\n  Backbone: 28,854,368 total, 0 trainable\n  Detection Head: 881,686 total, 881,686 trainable\n\nTesting forward pass...\nForward pass successful!\nOutput: 2 elements\n  [0]: torch.Size([1, 6, 8400])\n  [1]: <class 'list'>\nyes\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"\n\nyaml_content = \"\"\"\n    path: /kaggle/input/home-fire-dataset\n    train: train/images\n    val: val/images\n    test: test/images\n    \n    nc: 2\n    names: ['fire', 'smoke']\n    \"\"\"\n\nwith open(\"/kaggle/working/home-fire.yaml\", \"w\") as f:\n    f.write(yaml_content)\n\n                                                                            ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T23:39:38.606330Z","iopub.execute_input":"2025-09-10T23:39:38.606618Z","iopub.status.idle":"2025-09-10T23:39:38.610995Z","shell.execute_reply.started":"2025-09-10T23:39:38.606599Z","shell.execute_reply":"2025-09-10T23:39:38.610132Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"\n\nclass ConvNextYOLOTrainer(DetectionTrainer):\n    def get_model(self, cfg=None, weights=None, verbose=True):\n        \"\"\"\n        Override YOLO model loading with our custom ConvNeXt backbone.\n        \"\"\"\n        # Initialize your custom YOLO model\n        weights_path = download_convnext_weights(\"convnext_tiny_1k\")\n        model = WorkingConvNextYOLO(\n            yolo_path=\"yolov8n.pt\",\n            num_classes=self.data[\"nc\"],     # number of dataset classes\n            convnext_weights_path = weights_path,      # or your convnext pretrained weights\n            freeze_backbone=True             # freeze backbone if needed\n        ).yolo\n\n        \n        keys = [\"box\", \"cls\", \"dfl\", \"pose\", \"kobj\"]\n        hyp_dict = {k: getattr(self.args, k) for k in keys if hasattr(self.args, k)}\n        print(\"⚠️ Building hyp from args:\", hyp_dict)\n        self.hyp = SimpleNamespace(**hyp_dict)\n            \n        print(\"done#########################\")\n        # Load weights if provided\n        \n        print(\"done2#########################################\")\n         # Build SimpleNamespace for hyp\n        keys = [\"box\", \"cls\", \"dfl\", \"pose\", \"kobj\"]\n        hyp_dict = {k: getattr(self.args, k) for k in keys if hasattr(self.args, k)}\n        hyp_ns = SimpleNamespace(**hyp_dict)\n\n        # Attach hyp to the model (NOT to args)\n        model.model.args = hyp_ns\n        print(model.args)\n        # Initialize loss so the trainer can call it\n        model.init_criterion()  # ensures self.criterion exists\n        \n        return model\nimport torch, gc\ngc.collect()\ntorch.cuda.empty_cache()\nargs = dict(\n    model=\"yolov8n.pt\",   # dummy, will be replaced by get_model()\n    data=\"/kaggle/working/home-fire.yaml\",  # your dataset yaml\n    epochs=50,\n    imgsz=640,\n    batch=8\n)\n\ntrainer = ConvNextYOLOTrainer(overrides=args)\nprint(\"trainer is ready\")\n\n# Build hyp from args manually\n# Do NOT assign to trainer.args.hyp\n# trainer.args.hyp = trainer.hyp  <-- remove this line\n\n\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T23:39:41.285106Z","iopub.execute_input":"2025-09-10T23:39:41.285372Z","iopub.status.idle":"2025-09-10T23:40:52.057186Z","shell.execute_reply.started":"2025-09-10T23:39:41.285353Z","shell.execute_reply":"2025-09-10T23:40:52.055230Z"}},"outputs":[{"name":"stdout","text":"Ultralytics 8.3.198 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/home-fire.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/runs/detect/train, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% ━━━━━━━━━━━━ 755.1KB 26.4MB/s 0.0s\ntrainer is ready\n✅ Found existing weights: convnext_tiny_1k.pth\nCreating Working ConvNext-YOLO...\nOriginal YOLO type: <class 'ultralytics.nn.tasks.DetectionModel'>\nModel layers type: <class 'torch.nn.modules.container.Sequential'>\nNumber of layers: 23\nReplacing backbone with ConvNeXt...\n🔄 Loading pretrained weights from convnext_tiny_1k.pth\n✅ Pretrained weights loaded successfully!\n✅ ConvNext Tiny backbone ready for YOLO integration\n📊 Feature channels: [192, 384, 768] → [256, 512, 1024]\nswapped\nFreezing ConvNeXt backbone...\nUpdating detection head: -> 2 classes\nFound detection layer: <class 'ultralytics.nn.modules.head.Detect'>\n  Updated cv2[0]: 64 -> 2\n  Updated cv2[1]: 64 -> 2\n  Updated cv2[2]: 64 -> 2\n  Updated cv3[0]: 80 -> 64\n  Updated cv3[1]: 80 -> 64\n  Updated cv3[2]: 80 -> 64\nEnsuring neck and head are trainable...\n\nParameter Summary:\n  Total: 31,995,590 (32.0M)\n  Trainable: 3,141,222 (3.1M)\n  Frozen: 28,854,368 (28.9M)\n  Trainable Ratio: 9.8%\n\nComponent Breakdown:\n  Backbone: 28,854,368 total, 0 trainable\n  Detection Head: 881,686 total, 881,686 trainable\n⚠️ Building hyp from args: {'box': 7.5, 'cls': 0.5, 'dfl': 1.5, 'pose': 12.0, 'kobj': 1.0}\ndone#########################\ndone2#########################################\n{'task': 'detect', 'data': 'coco.yaml', 'imgsz': 640, 'single_cls': False, 'model': 'yolov8n.pt'}\nFreezing layer 'model.22.dfl.conv.weight'\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.downsample_layers.0.0.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.downsample_layers.0.0.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.downsample_layers.0.1.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.downsample_layers.0.1.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.downsample_layers.1.0.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.downsample_layers.1.0.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.downsample_layers.1.1.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.downsample_layers.1.1.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.downsample_layers.2.0.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.downsample_layers.2.0.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.downsample_layers.2.1.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.downsample_layers.2.1.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.downsample_layers.3.0.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.downsample_layers.3.0.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.downsample_layers.3.1.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.downsample_layers.3.1.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.0.0.gamma'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.0.0.dwconv.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.0.0.dwconv.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.0.0.norm.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.0.0.norm.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.0.0.pwconv1.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.0.0.pwconv1.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.0.0.pwconv2.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.0.0.pwconv2.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.0.1.gamma'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.0.1.dwconv.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.0.1.dwconv.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.0.1.norm.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.0.1.norm.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.0.1.pwconv1.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.0.1.pwconv1.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.0.1.pwconv2.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.0.1.pwconv2.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.0.2.gamma'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.0.2.dwconv.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.0.2.dwconv.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.0.2.norm.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.0.2.norm.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.0.2.pwconv1.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.0.2.pwconv1.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.0.2.pwconv2.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.0.2.pwconv2.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.1.0.gamma'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.1.0.dwconv.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.1.0.dwconv.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.1.0.norm.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.1.0.norm.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.1.0.pwconv1.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.1.0.pwconv1.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.1.0.pwconv2.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.1.0.pwconv2.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.1.1.gamma'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.1.1.dwconv.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.1.1.dwconv.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.1.1.norm.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.1.1.norm.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.1.1.pwconv1.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.1.1.pwconv1.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.1.1.pwconv2.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.1.1.pwconv2.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.1.2.gamma'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.1.2.dwconv.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.1.2.dwconv.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.1.2.norm.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.1.2.norm.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.1.2.pwconv1.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.1.2.pwconv1.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.1.2.pwconv2.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.1.2.pwconv2.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.0.gamma'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.0.dwconv.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.0.dwconv.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.0.norm.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.0.norm.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.0.pwconv1.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.0.pwconv1.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.0.pwconv2.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.0.pwconv2.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.1.gamma'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.1.dwconv.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.1.dwconv.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.1.norm.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.1.norm.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.1.pwconv1.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.1.pwconv1.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.1.pwconv2.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.1.pwconv2.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.2.gamma'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.2.dwconv.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.2.dwconv.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.2.norm.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.2.norm.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.2.pwconv1.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.2.pwconv1.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.2.pwconv2.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.2.pwconv2.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.3.gamma'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.3.dwconv.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.3.dwconv.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.3.norm.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.3.norm.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.3.pwconv1.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.3.pwconv1.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.3.pwconv2.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.3.pwconv2.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.4.gamma'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.4.dwconv.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.4.dwconv.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.4.norm.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.4.norm.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.4.pwconv1.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.4.pwconv1.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.4.pwconv2.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.4.pwconv2.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.5.gamma'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.5.dwconv.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.5.dwconv.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.5.norm.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.5.norm.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.5.pwconv1.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.5.pwconv1.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.5.pwconv2.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.5.pwconv2.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.6.gamma'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.6.dwconv.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.6.dwconv.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.6.norm.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.6.norm.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.6.pwconv1.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.6.pwconv1.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.6.pwconv2.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.6.pwconv2.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.7.gamma'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.7.dwconv.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.7.dwconv.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.7.norm.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.7.norm.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.7.pwconv1.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.7.pwconv1.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.7.pwconv2.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.7.pwconv2.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.8.gamma'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.8.dwconv.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.8.dwconv.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.8.norm.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.8.norm.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.8.pwconv1.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.8.pwconv1.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.8.pwconv2.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.2.8.pwconv2.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.3.0.gamma'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.3.0.dwconv.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.3.0.dwconv.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.3.0.norm.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.3.0.norm.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.3.0.pwconv1.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.3.0.pwconv1.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.3.0.pwconv2.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.3.0.pwconv2.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.3.1.gamma'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.3.1.dwconv.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.3.1.dwconv.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.3.1.norm.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.3.1.norm.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.3.1.pwconv1.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.3.1.pwconv1.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.3.1.pwconv2.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.3.1.pwconv2.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.3.2.gamma'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.3.2.dwconv.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.3.2.dwconv.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.3.2.norm.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.3.2.norm.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.3.2.pwconv1.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.3.2.pwconv1.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.3.2.pwconv2.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.convnext.stages.3.2.pwconv2.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.adapters.0.0.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.adapters.0.1.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.adapters.0.1.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.adapters.1.0.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.adapters.1.1.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.adapters.1.1.bias'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.adapters.2.0.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.adapters.2.1.weight'. See ultralytics.engine.trainer for customization of frozen layers.\nWARNING ⚠️ setting 'requires_grad=True' for frozen layer 'backbone.adapters.2.1.bias'. See ultralytics.engine.trainer for customization of frozen layers.\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% ━━━━━━━━━━━━ 5.4MB 86.5MB/s 0.1s\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.3±0.3 ms, read: 19.7±10.0 MB/s, size: 462.9 KB)\n\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/input/home-fire-dataset/train/labels... 3900 images, 87 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 3900/3900 169.3it/s 23.0s<0.1s\nWARNING ⚠️ \u001b[34m\u001b[1mtrain: \u001b[0mCache directory /kaggle/input/home-fire-dataset/train is not writeable, cache not saved.\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 27.0±12.9 MB/s, size: 279.6 KB)\n\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/home-fire-dataset/val/labels... 1300 images, 33 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 1300/1300 167.0it/s 7.8s0.1s\nWARNING ⚠️ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/home-fire-dataset/val is not writeable, cache not saved.\nPlotting labels to /kaggle/working/runs/detect/train/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 60 weight(decay=0.0), 165 weight(decay=0.0005), 146 bias(decay=0.0)\nImage sizes 640 train, 640 val\nUsing 4 dataloader workers\nLogging results to \u001b[1m/kaggle/working/runs/detect/train\u001b[0m\nStarting training for 50 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       1/50      1.46G       3.56      389.5      5.653         16        640: 20% ━━────────── 99/488 18.1it/s 15.3s<21.5s\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/3731921333.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setup_scheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36m_do_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    414\u001b[0m                     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m                     \u001b[0;31m# decouple inference and loss calculations for torch.compile convenience\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m                     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"img\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m                     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munwrap_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/nn/tasks.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# for cases of training and validating while training.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprofile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/nn/tasks.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, profile, visualize, augment, embed)\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maugment\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict_augment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprofile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_predict_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprofile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/nn/tasks.py\u001b[0m in \u001b[0;36m_predict_once\u001b[0;34m(self, x, profile, visualize, embed)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mprofile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_profile_one_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# save output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/nn/modules/block.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;34m\"\"\"Forward pass through C2f layer.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/nn/modules/block.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;34m\"\"\"Forward pass through C2f layer.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/nn/modules/block.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    493\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0;34m\"\"\"Apply bottleneck with optional shortcut connection.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOutput\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \"\"\"\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward_fuse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0mused\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnormalization\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meval\u001b[0m \u001b[0mmode\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mbuffers\u001b[0m \u001b[0mare\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \"\"\"\n\u001b[0;32m--> 193\u001b[0;31m         return F.batch_norm(\n\u001b[0m\u001b[1;32m    194\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m             \u001b[0;31m# If buffers are not to be tracked, ensure that they won't be updated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2820\u001b[0m         \u001b[0m_verify_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2821\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2822\u001b[0;31m     return torch.batch_norm(\n\u001b[0m\u001b[1;32m   2823\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2824\u001b[0m         \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":25},{"cell_type":"code","source":"from ultralytics import YOLO\n\nultra_model = YOLO(\"/kaggle/working/runs/detect/train2/weights/best.pt\")\n\n# Save only state_dict for future use\ntorch.save(ultra_model.model.state_dict(), \"best_state_dict.pth\")\nstate_dict = torch.load(\"best_state_dict.pth\", map_location=\"cpu\")\nmissing, unexpected = model.load_state_dict(state_dict, strict=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T23:41:21.058018Z","iopub.execute_input":"2025-09-10T23:41:21.058667Z","iopub.status.idle":"2025-09-10T23:41:21.318289Z","shell.execute_reply.started":"2025-09-10T23:41:21.058616Z","shell.execute_reply":"2025-09-10T23:41:21.317213Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/1168764843.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0multralytics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0multra_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/kaggle/working/runs/detect/train2/weights/best.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Save only state_dict for future use\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/models/yolo/model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, task, verbose)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;31m# Continue with default YOLO initialization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"model\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"RTDETR\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# if RTDETR head\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mfrom\u001b[0m \u001b[0multralytics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRTDETR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, task, verbose)\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;31m# Delete super().training for accessing self.model.training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(self, weights, task)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mckpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moverrides\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset_ckpt_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/nn/tasks.py\u001b[0m in \u001b[0;36mload_checkpoint\u001b[0;34m(weight, device, inplace, fuse)\u001b[0m\n\u001b[1;32m   1500\u001b[0m         \u001b[0mckpt\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mModel\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1501\u001b[0m     \"\"\"\n\u001b[0;32m-> 1502\u001b[0;31m     \u001b[0mckpt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch_safe_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# load ckpt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1503\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mDEFAULT_CFG_DICT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train_args\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m  \u001b[0;31m# combine model and default args, preferring model args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1504\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mckpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ema\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mckpt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# FP32 model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/nn/tasks.py\u001b[0m in \u001b[0;36mtorch_safe_load\u001b[0;34m(weight, safe_only)\u001b[0m\n\u001b[1;32m   1447\u001b[0m                     \u001b[0mckpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msafe_pickle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1448\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1449\u001b[0;31m                 \u001b[0mckpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1451\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mModuleNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# e.name is missing module name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/utils/patches.py\u001b[0m in \u001b[0;36mtorch_load\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"weights_only\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1423\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1425\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1426\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1427\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    749\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    752\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"w\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/working/runs/detect/train2/weights/best.pt'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/kaggle/working/runs/detect/train2/weights/best.pt'","output_type":"error"}],"execution_count":26},{"cell_type":"code","source":"\ntest_images = glob.glob(\"/kaggle/input/home-fire-dataset/test/images/*.jpg\")  # adjust path if needed\nprint(len(test_images))\n# Pick a few random samples\nsample_images = random.sample(test_images, 5)\n\nfor img_path in sample_images:\n    results = ultra_model(img_path)  # run inference\n    \n    # Save or display results\n    results[0].show()   # display in notebook (OpenCV window in local env)\n    results[0].save(filename=f\"/kaggle/working/preds_{img_path.split('/')[-1]}\")\nfor img_path in sample_images:\n    results = model(img_path)\n    annotated = results[0].plot()  # numpy array (BGR)\n    \n    # Convert BGR → RGB for matplotlib\n    plt.imshow(cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB))\n    plt.axis(\"off\")\n    plt.title(img_path.split(\"/\")[-1])\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T23:13:59.959879Z","iopub.status.idle":"2025-09-10T23:13:59.960259Z","shell.execute_reply.started":"2025-09-10T23:13:59.960072Z","shell.execute_reply":"2025-09-10T23:13:59.960096Z"}},"outputs":[],"execution_count":null}]}